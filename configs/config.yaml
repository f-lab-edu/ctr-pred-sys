model:
  LGBM:
    objective: "binary"
    metric: "binary_logloss"
    boosting_type: "gbdt"
    learning_rate: 0.05
    num_leaves: 31
    max_depth: -1
    min_data_in_leaf: 20
    feature_fraction: 0.8
    bagging_fraction: 0.8
    bagging_freq: 5
    verbose: -1
    seed: 42
    num_boost_round: 1000
    early_stopping_rounds: 50
  DeepFM:
    embedding_dim: 8
    deep_dims: [128, 64]
    dropout: 0.3
  DCNv2:
    embedding_dim: 8
    deep_dims: [128, 64]
    cross_layers: 3
    dropout: 0.3

training:
  batch_size: 256
  epochs: 10
  learning_rate: 0.001
  random_seed: 42

data:
  dataset_path: "./data/day_0_sample_10000"
  test_split: 0.2